{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CEM_df_2017_H_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2017_MAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2017_M_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2017_WOMAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2018_H_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2018_MAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2018_M_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2018_WOMAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2019_H_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2019_MAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2019_M_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2019_WOMAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2020_H_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2020_MAN_VICTIM_DAYS.csv\",delimiter=\",\")\n",
    "CEM_df_2020_M_DAYS = pd.read_csv(\"./CEM_DATA_PREPROCESSED_2020_WOMAN_VICTIM_DAYS.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_df_2018_H_DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasar los casos del 12/31/2017 al 2018 (semana 53)\n",
    "#pasar los casos 12/30/2018 y 12/31/2018 asl 2019 (semana 105)\n",
    "#pasar los casos del 12/29/2019 12/30/2019 y 12/31/2019 al 2020 (semana 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_2017_TO_2018_H = CEM_df_2017_H_DAYS[CEM_df_2017_H_DAYS['week']==53]##.reset_index(drop=True)\n",
    "FROM_2017_TO_2018_M = CEM_df_2017_M_DAYS[CEM_df_2017_M_DAYS['week']==53]##.reset_index(drop=True)\n",
    "\n",
    "FROM_2018_TO_2019_H = CEM_df_2018_H_DAYS[CEM_df_2018_H_DAYS['week']==105]##.reset_index(drop=True)\n",
    "FROM_2018_TO_2019_M = CEM_df_2018_M_DAYS[CEM_df_2018_M_DAYS['week']==105]##.reset_index(drop=True)\n",
    "\n",
    "FROM_2019_TO_2020_H = CEM_df_2019_H_DAYS[CEM_df_2019_H_DAYS['week']==157]##.reset_index(drop=True)\n",
    "FROM_2019_TO_2020_M = CEM_df_2019_M_DAYS[CEM_df_2019_M_DAYS['week']==157]##.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out_2017_H = FROM_2017_TO_2018_H.index\n",
    "index_out_2017_M = FROM_2017_TO_2018_M.index\n",
    "\n",
    "index_out_2018_H = FROM_2018_TO_2019_H.index\n",
    "index_out_2018_M = FROM_2018_TO_2019_M.index\n",
    "\n",
    "index_out_2019_H = FROM_2019_TO_2020_H.index\n",
    "index_out_2019_M = FROM_2019_TO_2020_M.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_out_2018_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retiro de filas\n",
    "\n",
    "CEM_df_2017_H_DAYS = CEM_df_2017_H_DAYS.drop(CEM_df_2017_H_DAYS.index [ index_out_2017_H])\n",
    "CEM_df_2017_M_DAYS = CEM_df_2017_M_DAYS.drop(CEM_df_2017_M_DAYS.index [ index_out_2017_M])\n",
    "\n",
    "CEM_df_2018_H_DAYS = CEM_df_2018_H_DAYS.drop(CEM_df_2018_H_DAYS.index [ index_out_2018_H])\n",
    "CEM_df_2018_M_DAYS = CEM_df_2018_M_DAYS.drop(CEM_df_2018_M_DAYS.index [ index_out_2018_M])\n",
    "\n",
    "CEM_df_2019_H_DAYS = CEM_df_2019_H_DAYS.drop(CEM_df_2019_H_DAYS.index [ index_out_2019_H])\n",
    "CEM_df_2019_M_DAYS = CEM_df_2019_M_DAYS.drop(CEM_df_2019_M_DAYS.index [ index_out_2019_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adici√≥n de filas\n",
    "CEM_df_2018_H_DAYS = pd.concat([CEM_df_2018_H_DAYS,FROM_2017_TO_2018_H])\n",
    "CEM_df_2018_M_DAYS = pd.concat([CEM_df_2018_M_DAYS,FROM_2017_TO_2018_M])\n",
    "\n",
    "CEM_df_2019_H_DAYS = pd.concat([CEM_df_2019_H_DAYS,FROM_2018_TO_2019_H])\n",
    "CEM_df_2019_M_DAYS = pd.concat([CEM_df_2019_M_DAYS,FROM_2018_TO_2019_M])\n",
    "\n",
    "CEM_df_2020_H_DAYS = pd.concat([CEM_df_2020_H_DAYS,FROM_2019_TO_2020_H])\n",
    "CEM_df_2020_M_DAYS = pd.concat([CEM_df_2020_M_DAYS,FROM_2019_TO_2020_M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_df_2017_H_DAYS = CEM_df_2017_H_DAYS.reset_index(drop=True)\n",
    "CEM_df_2017_M_DAYS = CEM_df_2017_M_DAYS.reset_index(drop=True)\n",
    "\n",
    "CEM_df_2018_H_DAYS = CEM_df_2018_H_DAYS.reset_index(drop=True)\n",
    "CEM_df_2018_M_DAYS = CEM_df_2018_M_DAYS.reset_index(drop=True)\n",
    "\n",
    "CEM_df_2019_H_DAYS = CEM_df_2019_H_DAYS.reset_index(drop=True)\n",
    "CEM_df_2019_M_DAYS = CEM_df_2019_M_DAYS.reset_index(drop=True)\n",
    "\n",
    "CEM_df_2020_H_DAYS = CEM_df_2020_H_DAYS.reset_index(drop=True)\n",
    "CEM_df_2020_M_DAYS = CEM_df_2020_M_DAYS.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_df_2018_H_DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGREGAMOS POR SEMANA\n",
    "def aggregate_for_week(base_df):\n",
    "    print(\"comenzando\")\n",
    "    districts = base_df['distr'].unique()\n",
    "    \n",
    "    fecha =[]\n",
    "    dep = []\n",
    "    distr = []\n",
    "    prov = []\n",
    "    week = []\n",
    "    \n",
    "    physical_v = []\n",
    "    sexual_v = []\n",
    "    economical_v = []\n",
    "    psychological_v = []\n",
    "    first_time = []\n",
    "    inf = []\n",
    "    nin = []\n",
    "    ado = []\n",
    "    ado_t = []\n",
    "    jov = []\n",
    "    adu = []\n",
    "    m60 = []\n",
    "    family = []\n",
    "    love = []\n",
    "    no_rel = []\n",
    "    aggr_alcohol = []\n",
    "    aggr_drug =[]\n",
    "    vict_disab = []\n",
    "    vict_alco = []\n",
    "    vict_drug = []\n",
    "    vict_lgtbi = []\n",
    "    \n",
    "    for d in districts:\n",
    "        \n",
    "        partial_df = base_df[base_df['distr'] == d].reset_index(drop=True)\n",
    "        dates = partial_df['week'].unique()\n",
    "        \n",
    "        for j in range(len(dates)):\n",
    "            physical_v_count = 0\n",
    "            sexual_v_count = 0\n",
    "            economical_v_count = 0\n",
    "            psychological_v_count = 0\n",
    "            first_time_count = 0\n",
    "            inf_count = 0\n",
    "            nin_count = 0\n",
    "            ado_count = 0\n",
    "            ado_t_count = 0\n",
    "            jov_count = 0\n",
    "            adu_count = 0\n",
    "            m60_count = 0\n",
    "            family_count = 0\n",
    "            love_count = 0\n",
    "            no_rel_count = 0\n",
    "            aggr_alcohol_count = 0\n",
    "            aggr_drug_count =0\n",
    "            vict_disab_count = 0\n",
    "            vict_alco_count = 0\n",
    "            vict_drug_count = 0\n",
    "            vict_lgtbi_count = 0\n",
    "            \n",
    "            first = True\n",
    "            for i in range(len(partial_df['distr'])):\n",
    "                if(partial_df['week'][i] == dates[j]):\n",
    "                    if(first):\n",
    "                        dep.append(partial_df['dep'][i])\n",
    "                        distr.append(partial_df['distr'][i])\n",
    "                        fecha.append(dates[j])\n",
    "                        prov.append(partial_df['prov'][i])\n",
    "                        week.append(partial_df['week'][i])\n",
    "                        first = False\n",
    "                        \n",
    "                    physical_v_count += partial_df['physical_v'][i]\n",
    "                    sexual_v_count += partial_df['sexual_v'][i]\n",
    "                    economical_v_count += partial_df['economical_v'][i]\n",
    "                    psychological_v_count += partial_df['psychological_v'][i]\n",
    "                    first_time_count += partial_df['first_time'][i]\n",
    "                    inf_count += partial_df['inf'][i]\n",
    "                    nin_count += partial_df['nin'][i]\n",
    "                    ado_count += partial_df['ado'][i]\n",
    "                    ado_t_count += partial_df['ado_t'][i]\n",
    "                    jov_count += partial_df['jov'][i]\n",
    "                    adu_count += partial_df['adu'][i]\n",
    "                    m60_count += partial_df['m60'][i]\n",
    "                    family_count += partial_df['family'][i]\n",
    "                    love_count += partial_df['love'][i]\n",
    "                    no_rel_count += partial_df['no_rel'][i]\n",
    "                    aggr_alcohol_count += partial_df['aggr_alcohol'][i]\n",
    "                    aggr_drug_count += partial_df['aggr_drug'][i]\n",
    "                    vict_disab_count += partial_df['vict_disab'][i]\n",
    "                    vict_alco_count += partial_df['vict_alco'][i]\n",
    "                    vict_drug_count += partial_df['vict_drug'][i]\n",
    "                    vict_lgtbi_count += partial_df['vict_lgtbi'][i]\n",
    "\n",
    "            physical_v.append(physical_v_count)\n",
    "            sexual_v.append(sexual_v_count)\n",
    "            economical_v.append(economical_v_count)\n",
    "            psychological_v.append(psychological_v_count)\n",
    "            first_time.append(first_time_count)\n",
    "            inf.append(inf_count)\n",
    "            nin.append(nin_count)\n",
    "            ado.append(ado_count)\n",
    "            ado_t.append(ado_t_count)\n",
    "            jov.append(jov_count)\n",
    "            adu.append(adu_count)\n",
    "            m60.append(m60_count)\n",
    "            family.append(family_count)\n",
    "            love.append(love_count)\n",
    "            no_rel.append(no_rel_count)\n",
    "            aggr_alcohol.append(aggr_alcohol_count)\n",
    "            aggr_drug.append(aggr_drug_count)\n",
    "            vict_disab.append(vict_disab_count)\n",
    "            vict_alco.append(vict_alco_count)\n",
    "            vict_drug.append(vict_drug_count)\n",
    "            vict_lgtbi.append(vict_lgtbi_count)\n",
    "            \n",
    "    #armamos df y retornamos\n",
    "    data = {'fecha':fecha,'distr':distr, 'prov' : prov, 'dep':dep, 'week':week, 'physical_v':physical_v,\n",
    "            'sexual_v':sexual_v, 'economical_v':economical_v, 'psychological_v':psychological_v, 'first_time':first_time,\n",
    "            'inf':inf, 'nin':nin, 'ado':ado,'ado_t':ado_t,'jov':jov,'adu':adu,'m60':m60,'family':family,'love':love,\n",
    "            'no_rel':no_rel,'aggr_alcohol':aggr_alcohol,'aggr_drug':aggr_drug,'vict_disab':vict_disab,'vict_alco':vict_alco,\n",
    "            'vict_drug':vict_drug,'vict_lgtbi':vict_lgtbi}\n",
    "    response_df = pd.DataFrame(data)\n",
    "    print(\"acabado\")\n",
    "    return response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_df_2017_H_WEEK = aggregate_for_week(CEM_df_2017_H_DAYS)\n",
    "CEM_df_2017_M_WEEK = aggregate_for_week(CEM_df_2017_M_DAYS)\n",
    "CEM_df_2018_H_WEEK = aggregate_for_week(CEM_df_2018_H_DAYS)\n",
    "CEM_df_2018_M_WEEK = aggregate_for_week(CEM_df_2018_M_DAYS)\n",
    "CEM_df_2019_H_WEEK = aggregate_for_week(CEM_df_2019_H_DAYS)\n",
    "CEM_df_2019_M_WEEK = aggregate_for_week(CEM_df_2019_M_DAYS)\n",
    "CEM_df_2020_H_WEEK = aggregate_for_week(CEM_df_2020_H_DAYS)\n",
    "CEM_df_2020_M_WEEK = aggregate_for_week(CEM_df_2020_M_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEM_df_2017_H_WEEK.to_csv('CEM_DATA_PREPROCESSED_2017_MAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2017_M_WEEK.to_csv('CEM_DATA_PREPROCESSED_2017_WOMAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2018_H_WEEK.to_csv('CEM_DATA_PREPROCESSED_2018_MAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2018_M_WEEK.to_csv('CEM_DATA_PREPROCESSED_2018_WOMAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2019_H_WEEK.to_csv('CEM_DATA_PREPROCESSED_2019_MAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2019_M_WEEK.to_csv('CEM_DATA_PREPROCESSED_2019_WOMAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2020_H_WEEK.to_csv('CEM_DATA_PREPROCESSED_2020_MAN_VICTIM_WEEKS.csv', index = False)\n",
    "CEM_df_2020_M_WEEK.to_csv('CEM_DATA_PREPROCESSED_2020_WOMAN_VICTIM_WEEKS.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
